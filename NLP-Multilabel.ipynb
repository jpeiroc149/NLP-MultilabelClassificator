{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PROCESAMIENTO DE LENGUAJE NATURAL**"
      ],
      "metadata": {
        "id": "rUxwdKKmuODl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "H0iw3P0MvPNg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Carga y preprocesamiento**"
      ],
      "metadata": {
        "id": "C9CP7MKXG3wS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este paso, estamos preparando los datos para el entrenamiento del modelo. Extraemos los textos de los tweets, que serán nuestras características (X), y separamos las etiquetas de sentimientos (y), que el modelo intentará predecir. Las columnas ID y Tweet se eliminan del conjunto de etiquetas, ya que no son necesarias para el modelado."
      ],
      "metadata": {
        "id": "KhGX2v-1Mc09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgMVE7BLuCtq",
        "outputId": "a1e3fcbe-1a60-49bf-c2f5-9151cfa4f465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3561 entries, 0 to 3560\n",
            "Data columns (total 13 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   ID            3561 non-null   object\n",
            " 1   Tweet         3561 non-null   object\n",
            " 2   anger         3561 non-null   bool  \n",
            " 3   anticipation  3561 non-null   bool  \n",
            " 4   disgust       3561 non-null   bool  \n",
            " 5   fear          3561 non-null   bool  \n",
            " 6   joy           3561 non-null   bool  \n",
            " 7   love          3561 non-null   bool  \n",
            " 8   optimism      3561 non-null   bool  \n",
            " 9   pessimism     3561 non-null   bool  \n",
            " 10  sadness       3561 non-null   bool  \n",
            " 11  surprise      3561 non-null   bool  \n",
            " 12  trust         3561 non-null   bool  \n",
            "dtypes: bool(11), object(2)\n",
            "memory usage: 94.0+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(              ID                                              Tweet  anger  \\\n",
              " 0  2018-Es-01643  @aliciaenp Ajajjaa somos del clan twitteras pe...  False   \n",
              " 1  2018-Es-05142  @AwadaNai la mala suerte del gato fichame la c...  False   \n",
              " 2  2018-Es-05379  @audiomano A mí tampoco me agrado mucho eso. E...   True   \n",
              " 3  2018-Es-00208  Para llevar a los bebes de un lugar a otro deb...  False   \n",
              " 4  2018-Es-01385  @DalasReview me encanta la terrible hipocresia...   True   \n",
              " \n",
              "    anticipation  disgust   fear    joy   love  optimism  pessimism  sadness  \\\n",
              " 0         False    False  False   True  False     False      False    False   \n",
              " 1         False    False   True  False  False     False       True    False   \n",
              " 2         False    False  False  False  False     False      False    False   \n",
              " 3         False    False  False   True  False     False      False    False   \n",
              " 4         False     True  False  False  False     False      False    False   \n",
              " \n",
              "    surprise  trust  \n",
              " 0     False  False  \n",
              " 1     False  False  \n",
              " 2     False  False  \n",
              " 3     False  False  \n",
              " 4     False  False  ,\n",
              "               ID                                              Tweet\n",
              " 0  2018-Es-06697  No me pienso perder la pelea de McGregor contr...\n",
              " 1  2018-Es-05385  Yo preocupada pensando que mi papá ya había ll...\n",
              " 2  2018-Es-03777  Pucha ya no me sirven todos los carros a Rondi...\n",
              " 3  2018-Es-02175  Si estar contigo es un delito, hago cien años ...\n",
              " 4  2018-Es-00726  @macacifuentesC @sergmujica Perfect... Y de un...,\n",
              " None)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los archivos CSV proporcionados\n",
        "train_df = pd.read_csv('sem_eval_train_es.csv')\n",
        "test_df = pd.read_csv('sem_eval_test_blank_es.csv')\n",
        "\n",
        "# Mostrar las primeras filas de cada dataframe para entender su estructura\n",
        "train_df_head = train_df.head()\n",
        "test_df_head = test_df.head()\n",
        "\n",
        "# Información sobre el dataframe de entrenamiento\n",
        "train_df_info = train_df.info()\n",
        "\n",
        "train_df_head, test_df_head, train_df_info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pasos previos: división y vectorización**"
      ],
      "metadata": {
        "id": "hynO0F3Wve0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar el rendimiento del modelo antes de aplicarlo a los datos de prueba, dividimos el conjunto de datos original en dos partes: el conjunto de entrenamiento (X_train, y_train), que contiene el 80% de los datos, y el conjunto de validación (X_val, y_val), que contiene el 20% restante. Esto nos permitirá verificar cómo generaliza el modelo a datos que no ha visto durante el entrenamiento."
      ],
      "metadata": {
        "id": "ZWDlI0a1MxQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar características (tweets) y etiquetas\n",
        "X = train_df['Tweet']\n",
        "y = train_df.drop(columns=['ID', 'Tweet'])\n",
        "\n",
        "# Dividir el conjunto de entrenamiento para validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un pipeline que vectorice el texto y entrene un modelo de clasificación\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000)),  # Convertir texto a TF-IDF\n",
        "    ('clf', MultiOutputClassifier(LogisticRegression(solver='lbfgs', max_iter=1000)))\n",
        "])"
      ],
      "metadata": {
        "id": "oKWpmdi2vUsh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí, configuramos un pipeline que combina dos pasos importantes:\n",
        "\n",
        "1.   **Vectorización del Texto:** Convertimos los tweets en vectores numéricos utilizando TF-IDF, lo que nos permite cuantificar la importancia de las palabras en cada tweet.\n",
        "2.   **Entrenamiento del Modelo:** Usamos un clasificador de regresión logística multietiqueta para predecir múltiples sentimientos para cada tweet.\n",
        "El pipeline nos facilita la aplicación secuencial de estos pasos tanto durante el entrenamiento como durante la predicción."
      ],
      "metadata": {
        "id": "fNmuZfO1NG-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Entrenamos...**"
      ],
      "metadata": {
        "id": "Yyfg8S2FwElb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, entrenamos el modelo utilizando el conjunto de entrenamiento. El pipeline previamente configurado realiza automáticamente el procesamiento del texto (vectorización TF-IDF) y el ajuste del modelo de regresión logística a los datos. Este entrenamiento permite al modelo aprender las relaciones entre los tweets y los sentimientos asociados.\n",
        "\n",
        "Una vez que el modelo ha sido entrenado, lo aplicamos al conjunto de validación para predecir las etiquetas de sentimiento. Estas predicciones nos permitirán evaluar el rendimiento del modelo en datos nuevos y determinar si está generalizando bien o si podría estar sobreajustado a los datos de entrenamiento.\n",
        "\n"
      ],
      "metadata": {
        "id": "Zfb7kQU1OAyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predecir en el conjunto de validación\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "# Reporte de clasificación\n",
        "report = classification_report(y_val, y_pred, target_names=y.columns, output_dict=True)\n",
        "\n",
        "report_summary = {label: report[label] for label in y.columns}\n",
        "report_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWLKVs9-vcMZ",
        "outputId": "480d1c44-c9b3-4ce5-cfd8-d4f9cb96e588"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'anger': {'precision': 0.648936170212766,\n",
              "  'recall': 0.2747747747747748,\n",
              "  'f1-score': 0.38607594936708867,\n",
              "  'support': 222.0},\n",
              " 'anticipation': {'precision': 0.0,\n",
              "  'recall': 0.0,\n",
              "  'f1-score': 0.0,\n",
              "  'support': 88.0},\n",
              " 'disgust': {'precision': 0.6,\n",
              "  'recall': 0.03296703296703297,\n",
              "  'f1-score': 0.0625,\n",
              "  'support': 91.0},\n",
              " 'fear': {'precision': 1.0,\n",
              "  'recall': 0.07575757575757576,\n",
              "  'f1-score': 0.14084507042253522,\n",
              "  'support': 66.0},\n",
              " 'joy': {'precision': 0.8727272727272727,\n",
              "  'recall': 0.22325581395348837,\n",
              "  'f1-score': 0.3555555555555555,\n",
              "  'support': 215.0},\n",
              " 'love': {'precision': 0.6666666666666666,\n",
              "  'recall': 0.0425531914893617,\n",
              "  'f1-score': 0.08,\n",
              "  'support': 47.0},\n",
              " 'optimism': {'precision': 0.0,\n",
              "  'recall': 0.0,\n",
              "  'f1-score': 0.0,\n",
              "  'support': 83.0},\n",
              " 'pessimism': {'precision': 0.0,\n",
              "  'recall': 0.0,\n",
              "  'f1-score': 0.0,\n",
              "  'support': 122.0},\n",
              " 'sadness': {'precision': 0.8709677419354839,\n",
              "  'recall': 0.17197452229299362,\n",
              "  'f1-score': 0.28723404255319146,\n",
              "  'support': 157.0},\n",
              " 'surprise': {'precision': 0.0,\n",
              "  'recall': 0.0,\n",
              "  'f1-score': 0.0,\n",
              "  'support': 40.0},\n",
              " 'trust': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 37.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente paso es evaluar el rendimiento del modelo utilizando un reporte de clasificación. Este reporte proporciona métricas clave como la precisión, el recall y la puntuación F1 para cada etiqueta de sentimiento. Estas métricas nos ayudan a entender cuán bien el modelo está prediciendo cada sentimiento en los tweets.\n",
        "\n",
        "* Precisión (precision): Mide la proporción de verdaderos positivos entre todos los casos predichos como positivos.\n",
        "\n",
        "* Recall (recall): Mide la proporción de verdaderos positivos entre todos los casos que son realmente positivos.\n",
        "\n",
        "* F1-score: Es la media armónica entre la precisión y el recall, proporcionando una única métrica para evaluar el rendimiento del modelo.\n",
        "\n",
        "Finalmente, extraemos un resumen del reporte para cada etiqueta de sentimiento, lo que facilita el análisis de los resultados y la identificación de áreas donde el modelo podría necesitar mejoras."
      ],
      "metadata": {
        "id": "xCjs4lL1OJDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Predecimos...**"
      ],
      "metadata": {
        "id": "lQzXSJSVwOc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este código, se entrena un modelo de clasificación multietiqueta para predecir los sentimientos asociados a tweets en un conjunto de datos ciego de prueba. El proceso comienza con la configuración y entrenamiento de un pipeline que combina la vectorización de texto mediante TF-IDF y un modelo de regresión logística multietiqueta. El modelo se entrena utilizando todo el conjunto de datos disponible, que incluye los tweets y sus correspondientes etiquetas de sentimientos.\n",
        "\n",
        "Una vez que el modelo ha sido entrenado, se aplica al conjunto ciego de prueba para predecir las probabilidades de cada sentimiento en cada tweet. Estas probabilidades indican la confianza del modelo en que un sentimiento específico está presente en un tweet. Para convertir estas probabilidades en decisiones binarias (es decir, etiquetas True o False), se define un umbral personalizado de 0.3. Esto significa que si la probabilidad de un sentimiento en un tweet es mayor o igual a 0.3, ese sentimiento se considera presente (True).\n",
        "\n",
        "El código también incluye un mecanismo para garantizar que cada tweet tenga al menos un sentimiento clasificado como True. Si todas las etiquetas para un tweet son False, el código selecciona la etiqueta con la probabilidad más alta y la marca como True. Esto evita que un tweet quede sin ningún sentimiento asignado. Las predicciones resultantes se organizan en un DataFrame, donde se aseguran de que las etiquetas estén en formato booleano (True/False). Además, se conserva la columna ID de los tweets originales para mantener la relación entre los tweets y sus predicciones.\n",
        "\n",
        "Finalmente, las predicciones se guardan en un archivo CSV con el nombre soluciones_jose_peiro_cardona.csv, siguiendo el formato requerido para la entrega."
      ],
      "metadata": {
        "id": "STPHs1ujO1SL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo usando todo el conjunto de entrenamiento\n",
        "pipeline.fit(X, y)\n",
        "\n",
        "# Predecir probabilidades en el conjunto ciego de prueba\n",
        "test_proba = pipeline.predict_proba(test_df['Tweet'])\n",
        "\n",
        "# Definir el umbral personalizado\n",
        "umbral = 0.3\n",
        "\n",
        "# Convertir las probabilidades a etiquetas binarias usando el umbral personalizado\n",
        "test_pred_custom = np.array([probas[:, 1] >= umbral for probas in test_proba]).T\n",
        "\n",
        "# Asegurar que al menos una etiqueta sea True por tweet\n",
        "for i in range(test_pred_custom.shape[0]):\n",
        "    if not test_pred_custom[i].any():\n",
        "        # Si todas las etiquetas son False, poner True en la etiqueta con la probabilidad más alta\n",
        "        test_pred_custom[i, np.argmax([probas[i, 1] for probas in test_proba])] = True\n",
        "\n",
        "# Crear un DataFrame con las predicciones\n",
        "predictions_df = pd.DataFrame(test_pred_custom, columns=y.columns)\n",
        "\n",
        "# Agregar la columna ID desde el test_df asegurando que se mantengan los IDs originales\n",
        "predictions_df.insert(0, 'ID', test_df['ID'])\n",
        "\n",
        "# Asegurarse de que las predicciones estén en formato booleano\n",
        "predictions_df = predictions_df.astype(bool)\n",
        "\n",
        "# Mantener la columna 'ID' en su formato original (object)\n",
        "predictions_df['ID'] = test_df['ID']\n",
        "\n",
        "# Guardar las predicciones en un archivo CSV\n",
        "output_filename = 'soluciones_jose_peiro_cardona.csv'\n",
        "predictions_df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f'Archivo guardado como {output_filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrmxDmKtwRzO",
        "outputId": "57d615cd-694d-4d12-fa1c-f2d9ae712bdb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo guardado como soluciones_jose_peiro_cardona.csv\n"
          ]
        }
      ]
    }
  ]
}